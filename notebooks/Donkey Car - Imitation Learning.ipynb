{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf_v1\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIR = os.path.dirname(os.path.abspath(\".\"))\n",
    "sys.path.insert(0, SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.model import DonkeyNet\n",
    "from src.utils import load_data, blur_img, data_generator, clip_steering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "DATA_PATH = r\"/home/rajk/Machine_Learning/DonkeyCar/data/\"\n",
    "img_key, steering_key, throttle_key = \"cam/image_array\", \"user/angle\", \"user/throttle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, Y = load_data(DATA_PATH, img_key=img_key, steering_key=steering_key, throttle_key=throttle_key, \n",
    "                 extensions=[\".json\"], exclude_files=[\"meta.json\"], crop_dim=(slice(20, -1),), \n",
    "                 verbose=verbose)\n",
    "# Filter out throttle readings\n",
    "Y = np.reshape(Y[:, 0], (len(Y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=853)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "version = 1\n",
    "input_shape = X_train[0].shape\n",
    "loss_func = tf_v1.losses.mean_squared_error\n",
    "optimizer = tf_v1.train.AdamOptimizer(learning_rate=1e-4)\n",
    "model = DonkeyNet(version=version, input_shape=input_shape, loss_func=loss_func, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH = os.path.join(SRC_DIR, \"models\", f\"DonkeyNetV{version}Model\", \"model.chkpt\")\n",
    "os.makedirs(os.path.dirname(SAVE_MODEL_PATH), exist_ok=True)\n",
    "GPU_OPTIONS = tf_v1.GPUOptions(per_process_gpu_memory_fraction=0.75)\n",
    "TF_CONFIG = tf_v1.ConfigProto(gpu_options=GPU_OPTIONS, allow_soft_placement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "with tf_v1.Session(config=TF_CONFIG) as sess:\n",
    "    sess.run(tf_v1.global_variables_initializer())\n",
    "    train_data_gen = data_generator(X_train, Y_train, epochs=epochs, batch_size=256, preprocessors=[blur_img])\n",
    "    test_data_gen = data_generator(X_test, Y_test, batch_size=1)\n",
    "    print(\"Training the model!\")\n",
    "    train_losses = model.run(sess, data_gen=train_data_gen, training=True)\n",
    "    print(f\"Mean training loss: {np.mean(train_losses):.3f}\")\n",
    "    print(\"Testing the model\")\n",
    "    test_losses = model.run(sess, data_gen=test_data_gen, training=False)\n",
    "    model.save_model(sess, SAVE_MODEL_PATH)\n",
    "    print(f\"Mean testing loss: {np.mean(test_losses):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=[20, 5], squeeze=False)\n",
    "axes[0, 0].set_title(\"Training losses\")\n",
    "axes[0, 0].plot(train_losses)\n",
    "axes[0, 1].set_title(\"Testing losses\")\n",
    "axes[0, 1].plot(test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RESTORE_MODEL_PATH = os.path.join(SRC_DIR, \"models\", \"model.chkpt\")\n",
    "with tf_v1.Session(config=TF_CONFIG) as sess:\n",
    "    sess.run(tf_v1.global_variables_initializer())\n",
    "    model.restore_model(sess, RESTORE_MODEL_PATH)\n",
    "    test_data_gen = data_generator(X_test, Y_test, batch_size=1)\n",
    "    test_losses = model.run(sess, data_gen=test_data_gen, training=False)\n",
    "plt.plot(test_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
