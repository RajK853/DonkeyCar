{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf_v1\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIR = os.path.dirname(os.path.abspath(\".\"))\n",
    "sys.path.insert(0, SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from src.model import DonkeyNet\n",
    "from src.utils import load_data, blur_img, data_generator, clip_steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "DATA_PATH = r\"/home/rajk/Machine_Learning/DonkeyCar/data/env_1/\"\n",
    "img_key, steering_key, throttle_key = \"cam/image_array\", \"user/angle\", \"user/throttle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files excluded: 1\n",
      "Found 15328 files with one of these extensions ['.json'] in '/home/rajk/Machine_Learning/DonkeyCar/data/env_1/'\n",
      " Loading images : ██████████████████████████████████████████████████ 100.00% (15328/15328)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%lprun -f load_data load_data(DATA_PATH, img_key=img_key, steering_key=steering_key, throttle_key=throttle_key, extensions=[\".json\"], exclude_files=[\"meta.json\"], verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files excluded: 1\n",
      "Found 15328 files with one of these extensions ['.json'] in '/home/rajk/Machine_Learning/DonkeyCar/data/env_1/'\n",
      " Loading images : ██████████████████████████████████████████████████ 100.00% (15328/15328)\n",
      "\n",
      "# Function load_data took 4.723 seconds!\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data(DATA_PATH, img_key=img_key, steering_key=steering_key, throttle_key=throttle_key, \n",
    "                 extensions=[\".json\"], exclude_files=[\"meta.json\"], verbose=verbose)\n",
    "# Filter out throttle readings\n",
    "Y = np.reshape(Y[:, 0], (len(Y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=853)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model DonkeyNetV1Model with 15 layers built!\n",
      "\n",
      "WARNING:tensorflow:From /home/rajk/miniconda3/envs/donkey/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "version = 1\n",
    "input_shape = X_train[0].shape\n",
    "loss_func = tf_v1.losses.mean_squared_error\n",
    "optimizer = tf_v1.train.AdamOptimizer(learning_rate=1e-4)\n",
    "model = DonkeyNet(version=version, input_shape=input_shape, loss_func=loss_func, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH = os.path.join(SRC_DIR, \"models\", f\"DonkeyNetV{version}Model\", \"model.chkpt\")\n",
    "os.makedirs(os.path.dirname(SAVE_MODEL_PATH), exist_ok=True)\n",
    "GPU_OPTIONS = tf_v1.GPUOptions(per_process_gpu_memory_fraction=0.75)\n",
    "TF_CONFIG = tf_v1.ConfigProto(gpu_options=GPU_OPTIONS, allow_soft_placement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "with tf_v1.Session(config=TF_CONFIG) as sess:\n",
    "    sess.run(tf_v1.global_variables_initializer())\n",
    "    train_data_gen = data_generator(X_train, Y_train, epochs=epochs, batch_size=256, preprocessors=[blur_img])\n",
    "    test_data_gen = data_generator(X_test, Y_test, batch_size=1)\n",
    "    print(\"Training the model!\")\n",
    "    train_losses = model.run(sess, data_gen=train_data_gen, training=True)\n",
    "    print(f\"Mean training loss: {np.mean(train_losses):.3f}\")\n",
    "    print(\"Testing the model\")\n",
    "    test_losses = model.run(sess, data_gen=test_data_gen, training=False)\n",
    "    model.save_model(sess, SAVE_MODEL_PATH)\n",
    "    print(f\"Mean testing loss: {np.mean(test_losses):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=[20, 5], squeeze=False)\n",
    "axes[0, 0].set_title(\"Training losses\")\n",
    "axes[0, 0].plot(train_losses)\n",
    "axes[0, 1].set_title(\"Testing losses\")\n",
    "axes[0, 1].plot(test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RESTORE_MODEL_PATH = os.path.join(SRC_DIR, \"models\", \"model.chkpt\")\n",
    "with tf_v1.Session(config=TF_CONFIG) as sess:\n",
    "    sess.run(tf_v1.global_variables_initializer())\n",
    "    model.restore_model(sess, RESTORE_MODEL_PATH)\n",
    "    test_data_gen = data_generator(X_test, Y_test, batch_size=1)\n",
    "    test_losses = model.run(sess, data_gen=test_data_gen, training=False)\n",
    "plt.plot(test_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
